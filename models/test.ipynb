{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import cv2\n",
    "import numpy as np\n",
    "from torchvision.transforms import Compose, Resize, ToTensor, Normalize\n",
    "from PIL import Image\n",
    "import plotly.graph_objects as go\n",
    "from transformers import pipeline\n",
    "import os\n",
    "\n",
    "def load_model():\n",
    "    device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "    checkpoint = \"depth-anything/Depth-Anything-V2-base-hf\"\n",
    "    pipe = pipeline(\"depth-estimation\", model=checkpoint, device=device)\n",
    "    return pipe\n",
    "\n",
    "def estimate_depth(model, img):\n",
    "    if isinstance(img, np.ndarray):\n",
    "        img_pil = Image.fromarray(cv2.cvtColor(img, cv2.COLOR_BGR2RGB))\n",
    "    else:\n",
    "        img_pil = img\n",
    "\n",
    "    predictions = model(img_pil)\n",
    "    depth_map = predictions[\"depth\"]\n",
    "    depth_map_np = np.array(depth_map).squeeze()\n",
    "    depth_map_resized = cv2.resize(depth_map_np, (img_pil.size[0], img_pil.size[1]))\n",
    "    \n",
    "    return depth_map_resized\n",
    "\n",
    "def process_image(model, image_path):\n",
    "    image = cv2.imread(image_path)\n",
    "    if image is None:\n",
    "        return None\n",
    "\n",
    "    depth_map = estimate_depth(model, image)\n",
    "    return image, depth_map\n",
    "\n",
    "def combine_depth_maps(depth_maps):\n",
    "    # Simple averaging of depth maps\n",
    "    return np.mean(depth_maps, axis=0)\n",
    "\n",
    "def create_point_cloud(images, depth_maps, sample_rate=10):\n",
    "    points = []\n",
    "    colors = []\n",
    "    \n",
    "    for img, depth in zip(images, depth_maps):\n",
    "        h, w = depth.shape\n",
    "        for y in range(0, h, sample_rate):\n",
    "            for x in range(0, w, sample_rate):\n",
    "                z = depth[y, x]\n",
    "                if z > 0:\n",
    "                    points.append([x, y, z])\n",
    "                    colors.append(img[y, x])\n",
    "    \n",
    "    return np.array(points), np.array(colors)\n",
    "\n",
    "def plot_3d_point_cloud(points, colors):\n",
    "    fig = go.Figure(data=[go.Scatter3d(\n",
    "        x=points[:, 0],\n",
    "        y=points[:, 1],\n",
    "        z=points[:, 2],\n",
    "        mode='markers',\n",
    "        marker=dict(\n",
    "            size=2,\n",
    "            color=['rgb({},{},{})'.format(r, g, b) for r, g, b in colors],\n",
    "            opacity=0.8\n",
    "        )\n",
    "    )])\n",
    "\n",
    "    fig.update_layout(\n",
    "        scene=dict(\n",
    "            xaxis_title='X',\n",
    "            yaxis_title='Y',\n",
    "            zaxis_title='Z',\n",
    "            aspectmode='data'\n",
    "        ),\n",
    "        margin=dict(l=0, r=0, b=0, t=0)\n",
    "    )\n",
    "\n",
    "    return fig\n",
    "\n",
    "def process_multiple_images(image_paths):\n",
    "    model = load_model()\n",
    "    images = []\n",
    "    depth_maps = []\n",
    "\n",
    "    for path in image_paths:\n",
    "        result = process_image(model, path)\n",
    "        if result is not None:\n",
    "            image, depth_map = result\n",
    "            images.append(image)\n",
    "            depth_maps.append(depth_map)\n",
    "\n",
    "    combined_depth = combine_depth_maps(depth_maps)\n",
    "    points, colors = create_point_cloud(images, depth_maps)\n",
    "    fig = plot_3d_point_cloud(points, colors)\n",
    "    \n",
    "    return fig\n",
    "\n",
    "# Example usage\n",
    "image_paths = ['path/to/image1.jpg', 'path/to/image2.jpg', 'path/to/image3.jpg']\n",
    "fig = process_multiple_images(image_paths)\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from PIL import Image\n",
    "import os\n",
    "\n",
    "def process_csv(csv_path, max_products=None):\n",
    "    # Read the CSV file\n",
    "    df = pd.read_csv(csv_path)\n",
    "    \n",
    "    # Extract product_id from meta\n",
    "    df['product_id'] = df['meta'].str.split(':').str[0]\n",
    "    \n",
    "    # Create is_main column\n",
    "    df['is_main'] = df['meta'].str.endswith(':main')\n",
    "    \n",
    "    # Add full path to images\n",
    "    df['full_path'] = \"../data/small/\" + df['path']\n",
    "    \n",
    "    # Group by product_id and aggregate\n",
    "    grouped = df.groupby('product_id').agg({\n",
    "        'full_path': lambda x: x.tolist(),\n",
    "        'is_main': 'any'\n",
    "    }).reset_index()\n",
    "    \n",
    "    # Separate main image and other images\n",
    "    grouped['main_image'] = grouped.apply(lambda row: next((path for path, is_main in zip(row['full_path'], df[df['product_id'] == row['product_id']]['is_main']) if is_main), None), axis=1)\n",
    "    grouped['other_images'] = grouped.apply(lambda row: [path for path, is_main in zip(row['full_path'], df[df['product_id'] == row['product_id']]['is_main']) if not is_main], axis=1)\n",
    "    \n",
    "    # Drop unnecessary columns\n",
    "    grouped = grouped.drop(columns=['full_path', 'is_main'])\n",
    "    \n",
    "    if max_products:\n",
    "        grouped = grouped.head(max_products)\n",
    "    \n",
    "    return grouped\n",
    "\n",
    "def lazy_load_image(path):\n",
    "    def load():\n",
    "        return Image.open(path)\n",
    "    return load\n",
    "\n",
    "def plot_images(row, max_images=9):\n",
    "    product_id = row['product_id']\n",
    "    image_paths = ([row['main_image']] if pd.notna(row['main_image']) else []) + row['other_images']\n",
    "    image_paths = image_paths[:max_images]  # Limit the number of images\n",
    "    \n",
    "    num_images = len(image_paths)\n",
    "    cols = 3\n",
    "    rows = (num_images + cols - 1) // cols\n",
    "    \n",
    "    fig, axes = plt.subplots(rows, cols, figsize=(15, 5 * rows))\n",
    "    fig.suptitle(f\"Images for Product ID: {product_id}\", fontsize=16)\n",
    "    \n",
    "    axes = axes.flatten() if hasattr(axes, 'flatten') else [axes]\n",
    "    \n",
    "    for i, path in enumerate(image_paths):\n",
    "        img = lazy_load_image(path)()\n",
    "        axes[i].imshow(img)\n",
    "        axes[i].axis('off')\n",
    "        axes[i].set_title('Main' if i == 0 and path == row['main_image'] else f'Other {i}')\n",
    "    \n",
    "    # Remove empty subplots\n",
    "    for i in range(num_images, len(axes)):\n",
    "        fig.delaxes(axes[i])\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "# Main execution\n",
    "csv_path = '../data/metadata/abo-mvr.csv'  # Replace with your actual CSV file path\n",
    "max_products = 10  # Set to None to process all products\n",
    "\n",
    "dataset = process_csv(csv_path, max_products)\n",
    "\n",
    "# Print information about the dataset\n",
    "print(\"Dataset structure:\")\n",
    "print(dataset.head())\n",
    "print(\"\\nDataset info:\")\n",
    "print(dataset.info())\n",
    "\n",
    "# Plot images for one product ID (for testing)\n",
    "test_row = dataset.iloc[0]  # Get the first row\n",
    "plot_images(test_row)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
